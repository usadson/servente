// Copyright (C) 2023 Tristan Gerritsen <tristan@thewoosh.org>
// All Rights Reserved.

//! This module contains the functionality for caching files in-memory. It
//! utilises  workers to cache files in the background, and watches the
//! filesystem for changes to files.
//!
//! Internally, it uses [stretto](https://docs.rs/stretto/latest/stretto/) to
//! cache files in memory, which is performant and correct, focussing on
//! reads over writes.

use std::{
    collections::HashMap,
    path::{Path, PathBuf},
    sync::{Arc, Mutex},
    time::Duration,
};

use lazy_static::lazy_static;
use stretto::AsyncCache;
use tokio::io::AsyncReadExt;

use super::compression::ContentEncodedVersions;

/// The maximum size of a file that can be cached in memory.
const FILE_CACHE_MAXIMUM_SIZE: u64 = 50_000_000; // 50 MB

/// The default cache duration for files. This is 1 hour, not infinite, because
/// it reduces the memory usage of the server for infrequently requested files.
const DEFAULT_CACHE_DURATION: Duration = Duration::from_secs(60 * 60);

lazy_static! {
    /// This is the cache that stores the files in memory. It is a static
    /// variable because it needs to be shared between all threads, but is
    /// concurrent.
    pub static ref FILE_CACHE: AsyncCache<String, Arc<ContentEncodedVersions>> = AsyncCache::new(12960, 1e6 as i64, tokio::spawn).unwrap();

    /// This is used to prevent multiple threads from caching the same file at
    /// the same time. It is a HashMap because it's faster to check if a file
    /// is already in the process of being cached, and is easier to remove the
    /// entry when the file is cached.
    static ref FILE_CACHE_CHECK_FILE_EXISTENCE: Mutex<HashMap<Arc<PathBuf>, ()>> = Mutex::new(HashMap::new());
}

/// Extra details about the file that's cached, which are generated by analysing
/// the files.
///
/// It provides extra information that can be used as hints by the server for
/// the client to optimise the loading of certain files.
#[derive(Clone, Debug)]
pub enum CachedFileDetails {
    /// `None` is specified for files that don't contain extra metadata or hints
    /// for the server.
    None,
    /// This is used for HTML files, which need to be parsed to find out which
    /// files need to be preloaded.
    Document {
        /// The list of files that need to be preloaded. This is a list of
        /// header values for the
        /// [`Link`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link)
        /// header.
        link_preloads: Vec<String>,
    },

    #[cfg(feature = "convert-markdown")]
    Markdown {
        html_rendered: Arc<ContentEncodedVersions>,
    }
}

/// Until this gets stabilized:
/// https://github.com/rust-lang/rust/issues/93610
fn arc_unwrap_or_clone<T>(arc: Arc<T>) -> T
        where T: Clone {
    Arc::try_unwrap(arc).unwrap_or_else(|arc| (*arc).clone())
}

/// Caches all the applicable files on startup.
fn cache_files_on_startup(path: &Path) -> Result<(), std::io::Error> {
    for path in std::fs::read_dir(path)? {
        if let Ok(entry) = path {
            tokio::task::spawn(async move {
                maybe_cache_file(&entry.path()).await;
            });
        }
    }

    Ok(())
}

/// Checks if a file is appropriate for caching.
///
/// It should only cache files that are smaller than the maximum size
/// (i.e. [FILE_CACHE_MAXIMUM_SIZE]).
fn is_file_appropriate_for_caching(metadata: &std::fs::Metadata) -> bool {
    if !metadata.is_file() {
        // Only cache files, not directories, sockets, pipes, etc.
        return false;
    }

    metadata.len() <= FILE_CACHE_MAXIMUM_SIZE
}

/// Checks if a file is already in the process of being cached, to avoid cache
/// races.
fn is_file_being_cached(path: &Arc<PathBuf>) -> bool {
    let mut cache_sync = FILE_CACHE_CHECK_FILE_EXISTENCE.lock().unwrap();
    match cache_sync.entry(Arc::clone(&path)) {
        std::collections::hash_map::Entry::Occupied(_) => {
            // File is already in the process of being cached.
            true
        }
        std::collections::hash_map::Entry::Vacant(entry) => {
            entry.insert(());
            false
        }
    }
}

/// Initiated by a request that didn't have this file in cache. This function
/// will check for the right conditions and stores the file in the cache if
/// necessary.
pub async fn maybe_cache_file(path: &Path) {
    let path = path.to_owned();

    tokio::task::spawn(async move {
        // Check if the file is allowed to be served.
        if !super::is_file_allowed_to_be_served(path.to_string_lossy().as_ref()) {
            return;
        }

        let path = Arc::new(path);

        if is_file_being_cached(&path) {
            return;
        }

        let start = std::time::Instant::now();
        let Ok(mut file) = tokio::fs::File::open(path.as_ref()).await else {
            return;
        };

        if let Ok(metadata) = file.metadata().await {
            if !is_file_appropriate_for_caching(&metadata) {
                return;
            }

            // Modified date is an `Option` since it might not be available on
            // some filesystems.
            let modified_date = metadata.modified().ok();
            let mut data = Vec::with_capacity(metadata.len() as usize);
            drop(metadata);

            _ = file.read_to_end(&mut data).await;

            let mut cached = ContentEncodedVersions::create(data);
            cached.modified_date = modified_date;

            // If the infrastructure around FILE_CACHE_CHECK_FILE_EXISTENCE
            // changes, `the arc_unwrap_or_clone` might be useful.
            let path_string = path_buf_to_string(arc_unwrap_or_clone(path.clone()));

            #[cfg(feature = "convert-markdown")]
            maybe_convert_markdown_htmlized(&path_string, &mut cached).await;

            // try_insert_with_ttl doesn't panic, so it's safer.
            // If due to an unfortunate event the file is cached twice, it's
            // not a big deal.
            _ = FILE_CACHE.try_insert_with_ttl(path_string, Arc::new(cached), 0, DEFAULT_CACHE_DURATION).await;

            // The file is cached, so another task may cache it again if
            // appropriately.
            FILE_CACHE_CHECK_FILE_EXISTENCE.lock().unwrap().remove(&path);

            println!("Cached file: {} in {} seconds", path.to_string_lossy(), (start.elapsed()).as_secs_f32());
        }
    });
}

/// Convert the file to HTML if it is a Markdown file.
#[cfg(feature = "convert-markdown")]
async fn maybe_convert_markdown_htmlized(path: &str, cached: &mut ContentEncodedVersions) {
    if cached.cache_details.is_some() {
        return;
    }

    if path.ends_with(".md") {
        let htmlized = servente_generator::common_mark::convert_to_html(String::from_utf8_lossy(cached.uncompressed.as_slice()).as_ref());

        let mut data = ContentEncodedVersions::create(htmlized.into());
        data.media_type = Some(crate::resources::MediaType::HTML);

        cached.cache_details = Some(CachedFileDetails::Markdown {
             html_rendered: Arc::new(data)
        });
    }
}

/// Converts a `PathBuf` to a `String`, trying without allocating.
fn path_buf_to_string(path: PathBuf) -> String {
    match path.into_os_string().into_string() {
        Ok(string) => string,
        Err(os_string) => os_string.to_string_lossy().to_string(),
    }
}

/// Called when the file is removed from the disk, so it should be pruned from
/// the memory cache as well.
fn remove_files_from_cache(paths: Vec<PathBuf>) {
    tokio::task::spawn(async move {
        for path in paths {
            FILE_CACHE.remove(&path.to_string_lossy().to_string()).await;
        }
    });
}

/// Starts the cache worker which makes sure that the cache is up to date.
///
/// It has the following features:
/// 1. Caches files on startup.
/// 2. Watches for file changes and updates the cache accordingly (behind a
///    feature flag).
pub async fn start(path: &Path) {
    let path_for_startup = path.to_owned();
    tokio::task::spawn_blocking(move || {
        if let Err(err) = cache_files_on_startup(&path_for_startup) {
            #[cfg(debug_assertions)]
            eprintln!("Failed to cache files on startup: {}", err);

            #[cfg(not(debug_assertions))]
            { _ = err }
        }
    });

    #[cfg(feature = "watch")]
    start_watcher(path);
}

/// Starts the watcher which watches for file changes and updates the cache
/// accordingly.
#[cfg(feature = "watch")]
fn start_watcher(path: &Path) {
    let path = path.to_owned();
    tokio::task::spawn_blocking(move || {
        use notify::{RecursiveMode, Watcher};

        let Ok(mut watcher) = notify::recommended_watcher(|result| {
            if let Ok(event) = result {
                let event: notify::Event = event;

                // If the file is removed, it should be pruned from the cache
                // as well.
                if event.kind.is_remove() {
                    remove_files_from_cache(event.paths);
                    return;
                }

                // The cached file in memory is stale, so we should update it.
                if event.kind.is_create() || event.kind.is_modify() {
                    for path in event.paths {
                        tokio::task::spawn(async move {
                            maybe_cache_file(&path).await;
                        });
                    }
                }
            }
        }) else {
            return;
        };

        _ = watcher.watch(&path, RecursiveMode::Recursive);
    });
}
